import streamlit as st
from openai import OpenAI

# Inicializa o cliente da OpenAI com a chave da API do Streamlit Secrets
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def gerar_prompts_por_nivel(tema):
    niveis = {
        1: f"Crie um prompt simples sobre: {tema}.",
        2: f"Crie um prompt com mais direcionamento sobre: {tema}.",
        3: f"Crie um prompt com par√¢metros espec√≠ficos para o tema: {tema}.",
        4: f"Crie um prompt com exemplos ou estilo desejado sobre: {tema}.",
        5: f"Crie um prompt com contexto, p√∫blico e objetivo claros sobre: {tema}.",
        6: f"""Crie um prompt nota 10, no mais alto n√≠vel de engenharia, sobre: {tema}. O prompt deve:
- Instruir o modelo a agir como um especialista no assunto
- Definir claramente o p√∫blico-alvo
- Definir estrutura, tom e formato da resposta
- Incluir restri√ß√µes ou objetivos espec√≠ficos
- Ser otimizado para performance m√°xima
- Estimular criatividade, profundidade e utilidade"""
    }

    resultados = {}
    for nivel, instrucoes in niveis.items():
        modelo = "gpt-4"  # tenta usar GPT-4
        try:
            resposta = client.chat.completions.create(
                model=modelo,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em engenharia de prompts."},
                    {"role": "user", "content": instrucoes}
                ],
                temperature=0.8
            )
        except Exception as e:
            if "model_not_found" in str(e) or "does not exist" in str(e):
                modelo = "gpt-3.5-turbo"  # fallback autom√°tico
                resposta = client.chat.completions.create(
                    model=modelo,
                    messages=[
                        {"role": "system", "content": "Voc√™ √© um especialista em engenharia de prompts."},
                        {"role": "user", "content": instrucoes}
                    ],
                    temperature=0.8
                )
            else:
                raise e
        resultados[nivel] = resposta.choices[0].message.content.strip()

    return resultados

# Interface Streamlit
st.set_page_config(page_title="Agente Neural de Prompts", layout="wide")
st.title("ü§ñ Agente Neural: Gera√ß√£o de Prompts em 6 N√≠veis")
tema = st.text_input("Digite o tema-base do prompt:")

if st.button("Gerar Prompts"):
    if tema.strip() == "":
        st.warning("Digite um tema antes de gerar.")
    else:
        st.info("Gerando prompts, aguarde...")
        try:
            resultados = gerar_prompts_por_nivel(tema)
            for nivel in range(1, 7):
                cor = "#38b000" if nivel == 6 else "#1f77b4"
                st.markdown(f"### üéØ N√≠vel {nivel} de complexidade")
                st.code(resultados[nivel], language="markdown")
                if nivel == 6:
                    st.markdown(f"üü¢ **Avalia√ß√£o:** Nota **10/10** ‚Äì Prompt de excel√™ncia.")
        except Exception as e:
            st.error(f"Erro ao gerar prompts: {e}")
